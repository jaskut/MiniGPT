{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('goethe/full.txt', 'r', encoding='utf-8') as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5854235\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie froh bin ich, daß ich weg bin!  Bester Freund, was ist das Herz\n",
      "des Menschen!  Dich zu verlassen, den ich so liebe, von dem ich\n",
      "unzertrennlich war, und froh zu sein!  Ich weiß, du verzeihst mir's.\n",
      "Waren nicht meine übrigen Verbindungen recht ausgesucht vom Schicksal,\n",
      "um ein Herz wie das meine zu ängstigen?  Die arme Leonore!  Und doch\n",
      "war ich unschuldig.  Konnt' ich dafür, daß, während die eigensinnigen\n",
      "Reize ihrer Schwester mir eine angenehme Unterhaltung verschafften,\n",
      "daß eine Leidenschaft in dem armen Herzen sich bildete?  Und doch--bin\n",
      "ich ganz unschuldig?  Hab' ich nicht ihre Empfindungen genährt?  Hab'\n",
      "ich mich nicht an den ganz wahren Ausdrücken der Natur, die uns so oft\n",
      "zu lachen machten, so wenig lächerlich sie waren, selbst ergetzt?\n",
      "Hab' ich nicht--o was ist der Mensch, daß er über sich klagen darf!\n",
      "Ich will, lieber Freund, ich verspreche dir's, ich will mich bessern,\n",
      "will nicht mehr ein bißchen Übel, das uns das Schicksal vorlegt,\n",
      "wiederkäuen, wie ich's immer getan habe;\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'()*+,-./0123456789:;<=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_abcdefghijklmnopqrstuvwxyz{}«»ÄÇÈÖÜßàâäèéêëòóöùûü—‘’“”„\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 59, 70, 70, 104, 61, 66, 63, 72]\n",
      "Hallöchen\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"Hallöchen\"))\n",
    "print(decode(encode(\"Hallöchen\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5854235]) torch.int64\n",
      "tensor([51, 67, 63,  1, 64, 76, 73, 66,  1, 60, 67, 72,  1, 67, 61, 66,  9,  1,\n",
      "        62, 59, 94,  1, 67, 61, 66,  1, 81, 63, 65,  1, 60, 67, 72,  2,  1,  1,\n",
      "        30, 63, 77, 78, 63, 76,  1, 34, 76, 63, 79, 72, 62,  9,  1, 81, 59, 77,\n",
      "         1, 67, 77, 78,  1, 62, 59, 77,  1, 36, 63, 76, 84,  0, 62, 63, 77,  1,\n",
      "        41, 63, 72, 77, 61, 66, 63, 72,  2,  1,  1, 32, 67, 61, 66,  1, 84, 79,\n",
      "         1, 80, 63, 76, 70, 59, 77, 77, 63, 72])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([51, 67, 63,  1, 64, 76, 73, 66,  1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "  # generate a small batch of data of inputs x and targets y\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "  return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "  for t in range(block_size): # time dimension\n",
    "    context = xb[b, :t+1]\n",
    "    target = yb[b,t]\n",
    "    print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "#single head of self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2,-1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3966, 0.6034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3069, 0.2892, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3233, 0.2175, 0.2443, 0.2149, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1479, 0.2034, 0.1663, 0.1455, 0.3369, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1259, 0.2490, 0.1324, 0.1062, 0.3141, 0.0724, 0.0000, 0.0000],\n",
       "         [0.1598, 0.1990, 0.1140, 0.1125, 0.1418, 0.1669, 0.1061, 0.0000],\n",
       "         [0.0845, 0.1197, 0.1078, 0.1537, 0.1086, 0.1146, 0.1558, 0.1553]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4016, 0.5984, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3365, 0.2271, 0.4364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3019, 0.2060, 0.2899, 0.2022, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1058, 0.1700, 0.1530, 0.3451, 0.2261, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1526, 0.1645, 0.1357, 0.2684, 0.1919, 0.0869, 0.0000, 0.0000],\n",
       "         [0.1103, 0.1711, 0.0761, 0.1654, 0.1667, 0.1643, 0.1461, 0.0000],\n",
       "         [0.1770, 0.1063, 0.1198, 0.0943, 0.1697, 0.1205, 0.1052, 0.1073]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4955, 0.5045, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2861, 0.3657, 0.3483, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1242, 0.3939, 0.1981, 0.2838, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3531, 0.1668, 0.1768, 0.1813, 0.1220, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1553, 0.1779, 0.1492, 0.1539, 0.1723, 0.1914, 0.0000, 0.0000],\n",
       "         [0.0722, 0.1255, 0.1119, 0.1896, 0.1537, 0.1918, 0.1552, 0.0000],\n",
       "         [0.1344, 0.1368, 0.0970, 0.1395, 0.1292, 0.1304, 0.0790, 0.1535]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5351, 0.4649, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3776, 0.4907, 0.1317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3079, 0.2849, 0.2206, 0.1865, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2074, 0.2611, 0.1368, 0.2071, 0.1876, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1733, 0.3004, 0.0656, 0.1682, 0.1669, 0.1255, 0.0000, 0.0000],\n",
       "         [0.1216, 0.1213, 0.1416, 0.1119, 0.1439, 0.2213, 0.1383, 0.0000],\n",
       "         [0.0925, 0.1598, 0.0945, 0.1355, 0.1356, 0.1086, 0.1185, 0.1548]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
